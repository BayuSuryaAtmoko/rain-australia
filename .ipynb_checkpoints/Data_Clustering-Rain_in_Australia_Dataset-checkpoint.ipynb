{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xL-Nk3m_eQsX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Dalam notebook ini kita akan menggunakan [Rain in Australia Dataset](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package) dari Kaggle. Untuk memulai kita akan memuat beberapa library dasar seperti Pandas, NumPy, Sklearn dll, kemudian membuat beberapa konfigurasi untuk beberapa library tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "uI1mGf-RdvlD"
   },
   "outputs": [],
   "source": [
    "# Meng-import library yang akan digunakan di proyek\n",
    "\n",
    "# Import libraries\n",
    "## Basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "## sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure libraries\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ml3cXrzkuZ0"
   },
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Sebelum kita dapat mulai membuat model kita, pertama-tama kita perlu memuat dan melakukan pre-process. Langkah ini memastikan bahwa model kita akan menerima data yang bagus untuk dipelajari, seperti \"a model is only as good as it's data\". Data pre-processing akan dibagi menjadi beberapa langkah seperti yang dijelaskan di bawah ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf8uFbzy57qd"
   },
   "source": [
    "## Loading data\n",
    "\n",
    "Pada langkah pertama ini kita akan memuat dataset yang telah diunggah di GitHub. Dokumentasi dataset dapat dilihat di [sini](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "qkY0_i5O586w",
    "outputId": "f9f8696f-f3bd-4eaa-e0a8-86dcca24b8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (145460, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mendapatkan data dari csv di github\n",
    "df_rain = pd.read_csv('https://raw.githubusercontent.com/BayuSuryaAtmoko/rain-australia/main/weatherAUS.csv')\n",
    "\n",
    "# Menampilkan ukuran data (instance dan attribute nya)\n",
    "print('Shape of dataframe:', df_rain.shape)\n",
    "\n",
    "# Menampilkan data sebanyak 5\n",
    "df_rain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzRRMcUkB7Ch"
   },
   "source": [
    "## Class Distribution\n",
    "\n",
    "Hal penting lainnya yang harus dipastikan sebelum memasukkan data kita ke dalam model adalah distribusi kelas dari data tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bP1q5SGTF3S-",
    "outputId": "f0387d37-d88e-4f3d-cb86-7a3e33d64d00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     110316\n",
       "Yes     31877\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan jumlah data \"RainTomorrow\" yang bernilai 0 dan 1\n",
    "\n",
    "df_rain['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKOO_Qj6odGa"
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "Hal terakhir yang harus diperiksa sebelum melanjutkan adalah missing values. Dalam beberapa kasus data mungkin memiliki nilai yang hilang (missing values) di beberapa kolom, hal ini dapat disebabkan beberapa alasan seperti human error. Kita dapat menggunakan fungsi `is_null()` dari Pandas untuk memeriksa data yang hilang dan kemudian menggunakan fungsi `sum()` untuk melihat total nilai yang hilang di setiap kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rz75ZKRIoWdK",
    "outputId": "98cadf6f-10c9-41d4-9222-be2756d2c01f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengecek apakah ada data instance yang memiliki data null(kosong)\n",
    "\n",
    "df_rain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfs6tnceaikB",
    "outputId": "b0e37819-a015-44a0-9976-0eeda79147e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Column : 145460\n",
      "\n",
      "Presentase missing data setiap kolom :\n",
      "                 column_name  percent_missing\n",
      "Date                    Date         0.000000\n",
      "Location            Location         0.000000\n",
      "MinTemp              MinTemp         1.020899\n",
      "MaxTemp              MaxTemp         0.866905\n",
      "Rainfall            Rainfall         2.241853\n",
      "Evaporation      Evaporation        43.166506\n",
      "Sunshine            Sunshine        48.009762\n",
      "WindGustDir      WindGustDir         7.098859\n",
      "WindGustSpeed  WindGustSpeed         7.055548\n",
      "WindDir9am        WindDir9am         7.263853\n",
      "WindDir3pm        WindDir3pm         2.906641\n",
      "WindSpeed9am    WindSpeed9am         1.214767\n",
      "WindSpeed3pm    WindSpeed3pm         2.105046\n",
      "Humidity9am      Humidity9am         1.824557\n",
      "Humidity3pm      Humidity3pm         3.098446\n",
      "Pressure9am      Pressure9am        10.356799\n",
      "Pressure3pm      Pressure3pm        10.331363\n",
      "Cloud9am            Cloud9am        38.421559\n",
      "Cloud3pm            Cloud3pm        40.807095\n",
      "Temp9am              Temp9am         1.214767\n",
      "Temp3pm              Temp3pm         2.481094\n",
      "RainToday          RainToday         2.241853\n",
      "RainTomorrow    RainTomorrow         2.245978\n"
     ]
    }
   ],
   "source": [
    "# Jika satu kolom mempunyai lebih dari 40% missing data, maka kolom itu akan dihapus.  \n",
    "\n",
    "# Total dari instans data\n",
    "totalColumn = len(df_rain)\n",
    "print('Total of Column :', totalColumn)\n",
    "\n",
    "# Menampilkan presentase missing data \n",
    "percent_missing = df_rain.isnull().sum() * 100 / totalColumn\n",
    "print('\\nPresentase missing data setiap kolom :')\n",
    "missing_value_df = pd.DataFrame({'column_name': df_rain.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "print(missing_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "EHfXe4jcnqkZ"
   },
   "outputs": [],
   "source": [
    "# Reusable function untuk menantukan aksi terhadap missing data\n",
    "def calculatePercentMissing(dataColumn, tittleColumn):\n",
    "\n",
    "  # Hitung presentase missing data pada kolom tertentu\n",
    "  totalColumn = len(df_rain)\n",
    "  percentMissingDataColumn = dataColumn.isnull().sum() * 100 / totalColumn\n",
    "  print('Presentase missing data kolom ' , tittleColumn , ' : ' , percentMissingDataColumn , ' %')\n",
    "\n",
    "  # Hapus kolom jika mempunyai lebih dari 40% missing data\n",
    "  if percentMissingDataColumn>40 :\n",
    "    df_rain.drop(tittleColumn, inplace=True, axis=1)\n",
    "    print(tittleColumn , ' mempunyai lebih dari 40% missing data maka akan dihapus.')\n",
    "  else :\n",
    "    # Data Interpolation\n",
    "    # Mengisi data null menggunakan data yang paling banyak muncul\n",
    "    df_rain[tittleColumn].fillna(df_rain[tittleColumn].mode()[0], inplace=True)\n",
    "    print(tittleColumn , ' digunakan untuk penelitian ini.')\n",
    "\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vzWHV1ikMF-",
    "outputId": "12e74b39-51df-4533-e680-a7f22bea5e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presentase missing data kolom  Date  :  0.0  %\n",
      "Date  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Location  :  0.0  %\n",
      "Location  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  MinTemp  :  1.0208992162793895  %\n",
      "MinTemp  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  MaxTemp  :  0.8669049910628351  %\n",
      "MaxTemp  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Rainfall  :  2.241853430496356  %\n",
      "Rainfall  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Evaporation  :  43.1665062560154  %\n",
      "Evaporation  mempunyai lebih dari 40% missing data maka akan dihapus.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Sunshine  :  48.00976213391998  %\n",
      "Sunshine  mempunyai lebih dari 40% missing data maka akan dihapus.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindGustDir  :  7.09885879279527  %\n",
      "WindGustDir  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindGustSpeed  :  7.055547916953114  %\n",
      "WindGustSpeed  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindDir9am  :  7.263852605527292  %\n",
      "WindDir9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindDir3pm  :  2.906641000962464  %\n",
      "WindDir3pm  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindSpeed9am  :  1.214766946239516  %\n",
      "WindSpeed9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  WindSpeed3pm  :  2.105046060772721  %\n",
      "WindSpeed3pm  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Humidity9am  :  1.8245565791282827  %\n",
      "Humidity9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Humidity3pm  :  3.09844630826344  %\n",
      "Humidity3pm  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Pressure9am  :  10.356799120033  %\n",
      "Pressure9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Pressure3pm  :  10.331362573903478  %\n",
      "Pressure3pm  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Cloud9am  :  38.42155919153032  %\n",
      "Cloud9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Cloud3pm  :  40.80709473394748  %\n",
      "Cloud3pm  mempunyai lebih dari 40% missing data maka akan dihapus.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Temp9am  :  1.214766946239516  %\n",
      "Temp9am  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  Temp3pm  :  2.4810944589577892  %\n",
      "Temp3pm  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  RainToday  :  2.241853430496356  %\n",
      "RainToday  digunakan untuk penelitian ini.\n",
      "\n",
      "\n",
      "Presentase missing data kolom  RainTomorrow  :  2.245978275814657  %\n",
      "RainTomorrow  digunakan untuk penelitian ini.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menantukan aksi terhadap missing data\n",
    "calculatePercentMissing(df_rain['Date'] , 'Date');\n",
    "calculatePercentMissing(df_rain['Location'] , 'Location');\n",
    "calculatePercentMissing(df_rain['MinTemp'] , 'MinTemp');\n",
    "calculatePercentMissing(df_rain['MaxTemp'] , 'MaxTemp');\n",
    "calculatePercentMissing(df_rain['Rainfall'] , 'Rainfall');\n",
    "calculatePercentMissing(df_rain['Evaporation'] , 'Evaporation');\n",
    "calculatePercentMissing(df_rain['Sunshine'] , 'Sunshine');\n",
    "calculatePercentMissing(df_rain['WindGustDir'] , 'WindGustDir');\n",
    "calculatePercentMissing(df_rain['WindGustSpeed'] , 'WindGustSpeed');\n",
    "calculatePercentMissing(df_rain['WindDir9am'] , 'WindDir9am');\n",
    "calculatePercentMissing(df_rain['WindDir3pm'] , 'WindDir3pm');\n",
    "calculatePercentMissing(df_rain['WindSpeed9am'] , 'WindSpeed9am');\n",
    "calculatePercentMissing(df_rain['WindSpeed3pm'] , 'WindSpeed3pm');\n",
    "calculatePercentMissing(df_rain['Humidity9am'] , 'Humidity9am');\n",
    "calculatePercentMissing(df_rain['Humidity3pm'] , 'Humidity3pm');\n",
    "calculatePercentMissing(df_rain['Pressure9am'] , 'Pressure9am');\n",
    "calculatePercentMissing(df_rain['Pressure3pm'] , 'Pressure3pm');\n",
    "calculatePercentMissing(df_rain['Cloud9am'] , 'Cloud9am');\n",
    "calculatePercentMissing(df_rain['Cloud3pm'] , 'Cloud3pm');\n",
    "calculatePercentMissing(df_rain['Temp9am'] , 'Temp9am');\n",
    "calculatePercentMissing(df_rain['Temp3pm'] , 'Temp3pm');\n",
    "calculatePercentMissing(df_rain['RainToday'] , 'RainToday');\n",
    "calculatePercentMissing(df_rain['RainTomorrow'] , 'RainTomorrow');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "SXcpHa8YwwKL",
    "outputId": "92e4c37c-a489-4210-ef79-711d4dc5852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Presentase missing data setiap kolom :\n",
      "                 column_name  percent_missing\n",
      "Date                    Date              0.0\n",
      "Location            Location              0.0\n",
      "MinTemp              MinTemp              0.0\n",
      "MaxTemp              MaxTemp              0.0\n",
      "Rainfall            Rainfall              0.0\n",
      "WindGustDir      WindGustDir              0.0\n",
      "WindGustSpeed  WindGustSpeed              0.0\n",
      "WindDir9am        WindDir9am              0.0\n",
      "WindDir3pm        WindDir3pm              0.0\n",
      "WindSpeed9am    WindSpeed9am              0.0\n",
      "WindSpeed3pm    WindSpeed3pm              0.0\n",
      "Humidity9am      Humidity9am              0.0\n",
      "Humidity3pm      Humidity3pm              0.0\n",
      "Pressure9am      Pressure9am              0.0\n",
      "Pressure3pm      Pressure3pm              0.0\n",
      "Cloud9am            Cloud9am              0.0\n",
      "Temp9am              Temp9am              0.0\n",
      "Temp3pm              Temp3pm              0.0\n",
      "RainToday          RainToday              0.0\n",
      "RainTomorrow    RainTomorrow              0.0\n",
      "\n",
      "\n",
      "Shape of dataframe: (145460, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6           W           44.0   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0         WNW           44.0   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0         WSW           46.0   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NE           24.0   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0           W           41.0   \n",
       "\n",
       "  WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
       "0          W        WNW          20.0          24.0         71.0         22.0   \n",
       "1        NNW        WSW           4.0          22.0         44.0         25.0   \n",
       "2          W        WSW          19.0          26.0         38.0         30.0   \n",
       "3         SE          E          11.0           9.0         45.0         16.0   \n",
       "4        ENE         NW           7.0          20.0         82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Temp9am  Temp3pm RainToday RainTomorrow  \n",
       "0       1007.7       1007.1       8.0     16.9     21.8        No           No  \n",
       "1       1010.6       1007.8       7.0     17.2     24.3        No           No  \n",
       "2       1007.6       1008.7       7.0     21.0     23.2        No           No  \n",
       "3       1017.6       1012.8       7.0     18.1     26.5        No           No  \n",
       "4       1010.8       1006.0       7.0     17.8     29.7        No           No  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan presentase missing data \n",
    "percent_missing = df_rain.isnull().sum() * 100 / totalColumn\n",
    "print('\\n')\n",
    "print('Presentase missing data setiap kolom :')\n",
    "missing_value_df = pd.DataFrame({'column_name': df_rain.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "print(missing_value_df)\n",
    "\n",
    "# Menampilkan ukuran data (instance dan attribute nya)\n",
    "print('\\n')\n",
    "print('Shape of dataframe:', df_rain.shape)\n",
    "\n",
    "# Menampilkan data sebanyak 5\n",
    "df_rain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>0.191328</td>\n",
       "      <td>-0.041360</td>\n",
       "      <td>-0.203581</td>\n",
       "      <td>W</td>\n",
       "      <td>0.327736</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.677819</td>\n",
       "      <td>0.623294</td>\n",
       "      <td>0.081409</td>\n",
       "      <td>-1.443652</td>\n",
       "      <td>-1.457215</td>\n",
       "      <td>-1.224564</td>\n",
       "      <td>0.995479</td>\n",
       "      <td>-0.014071</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>-0.751052</td>\n",
       "      <td>0.268745</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.327736</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>-1.124341</td>\n",
       "      <td>0.394836</td>\n",
       "      <td>-1.318948</td>\n",
       "      <td>-1.297105</td>\n",
       "      <td>-1.026898</td>\n",
       "      <td>-1.119521</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.032447</td>\n",
       "      <td>0.387799</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.353318</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>WSW</td>\n",
       "      <td>0.479465</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>0.565184</td>\n",
       "      <td>0.851751</td>\n",
       "      <td>-1.630138</td>\n",
       "      <td>-1.052860</td>\n",
       "      <td>-1.472054</td>\n",
       "      <td>-0.984466</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.227333</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>-0.468338</td>\n",
       "      <td>0.677518</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>NE</td>\n",
       "      <td>-1.189550</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.335896</td>\n",
       "      <td>-1.090136</td>\n",
       "      <td>-1.267083</td>\n",
       "      <td>-1.736746</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>-0.369217</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.171999</td>\n",
       "      <td>0.708731</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>0.835287</td>\n",
       "      <td>1.283631</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>W</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>-0.786436</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>0.651924</td>\n",
       "      <td>-0.906314</td>\n",
       "      <td>-0.997221</td>\n",
       "      <td>-1.389630</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.125481</td>\n",
       "      <td>1.175541</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location   MinTemp   MaxTemp  Rainfall WindGustDir  \\\n",
       "0  2008-12-01   Albury  0.191328 -0.041360 -0.203581           W   \n",
       "1  2008-12-02   Albury -0.751052  0.268745 -0.275097         WNW   \n",
       "2  2008-12-03   Albury  0.112796  0.353318 -0.275097         WSW   \n",
       "3  2008-12-04   Albury -0.468338  0.677518 -0.275097          NE   \n",
       "4  2008-12-05   Albury  0.835287  1.283631 -0.155903           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  \\\n",
       "0       0.327736          W        WNW      0.677819      0.623294   \n",
       "1       0.327736        NNW        WSW     -1.124341      0.394836   \n",
       "2       0.479465          W        WSW      0.565184      0.851751   \n",
       "3      -1.189550         SE          E     -0.335896     -1.090136   \n",
       "4       0.100143        ENE         NW     -0.786436      0.166379   \n",
       "\n",
       "   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am   Temp9am  \\\n",
       "0     0.081409    -1.443652    -1.457215    -1.224564  0.995479 -0.014071   \n",
       "1    -1.318948    -1.297105    -1.026898    -1.119521  0.608406  0.032447   \n",
       "2    -1.630138    -1.052860    -1.472054    -0.984466  0.608406  0.621667   \n",
       "3    -1.267083    -1.736746     0.011799    -0.369217  0.608406  0.171999   \n",
       "4     0.651924    -0.906314    -0.997221    -1.389630  0.608406  0.125481   \n",
       "\n",
       "    Temp3pm RainToday RainTomorrow  \n",
       "0  0.023104        No           No  \n",
       "1  0.387799        No           No  \n",
       "2  0.227333        No           No  \n",
       "3  0.708731        No           No  \n",
       "4  1.175541        No           No  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Menskalakan data numerik untuk menghindari keberadaan outlier yang dapat mempengaruhi model secara signifikan.\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Kolom attribute yang berisi data numerik\n",
    "# num_cols = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am' , 'Temp9am', 'Temp3pm']\n",
    "\n",
    "# # Menskalakan data numerik\n",
    "# scaler = StandardScaler()\n",
    "# df_rain[num_cols] = scaler.fit_transform(df_rain[num_cols])\n",
    "\n",
    "# # Menampilkan data sebanyak 5\n",
    "# df_rain.head(5)\n",
    "\n",
    "# Menskalakan data numerik untuk menghindari keberadaan outlier yang dapat mempengaruhi model secara signifikan.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Meng-copy original dataframe\n",
    "df_rain_ready = df_rain.copy()\n",
    "\n",
    "# Kolom attribute yang berisi data numerik\n",
    "num_cols = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am' , 'Temp9am', 'Temp3pm']\n",
    "\n",
    "# Menskalakan data numerik\n",
    "scaler = StandardScaler()\n",
    "df_rain_ready[num_cols] = scaler.fit_transform(df_rain_ready[num_cols])\n",
    "\n",
    "# Menampilkan data sebanyak 5\n",
    "df_rain_ready.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCphVkJe4Qo9"
   },
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "D7mgqU9d3o0D",
    "outputId": "55236fee-5c07-4007-f415-5d1930c055bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (145460, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191328</td>\n",
       "      <td>-0.041360</td>\n",
       "      <td>-0.203581</td>\n",
       "      <td>0.327736</td>\n",
       "      <td>0.677819</td>\n",
       "      <td>0.623294</td>\n",
       "      <td>0.081409</td>\n",
       "      <td>-1.443652</td>\n",
       "      <td>-1.457215</td>\n",
       "      <td>-1.224564</td>\n",
       "      <td>0.995479</td>\n",
       "      <td>-0.014071</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.751052</td>\n",
       "      <td>0.268745</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>0.327736</td>\n",
       "      <td>-1.124341</td>\n",
       "      <td>0.394836</td>\n",
       "      <td>-1.318948</td>\n",
       "      <td>-1.297105</td>\n",
       "      <td>-1.026898</td>\n",
       "      <td>-1.119521</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.032447</td>\n",
       "      <td>0.387799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.353318</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>0.479465</td>\n",
       "      <td>0.565184</td>\n",
       "      <td>0.851751</td>\n",
       "      <td>-1.630138</td>\n",
       "      <td>-1.052860</td>\n",
       "      <td>-1.472054</td>\n",
       "      <td>-0.984466</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.227333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.468338</td>\n",
       "      <td>0.677518</td>\n",
       "      <td>-0.275097</td>\n",
       "      <td>-1.189550</td>\n",
       "      <td>-0.335896</td>\n",
       "      <td>-1.090136</td>\n",
       "      <td>-1.267083</td>\n",
       "      <td>-1.736746</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>-0.369217</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.171999</td>\n",
       "      <td>0.708731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.835287</td>\n",
       "      <td>1.283631</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>-0.786436</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>0.651924</td>\n",
       "      <td>-0.906314</td>\n",
       "      <td>-0.997221</td>\n",
       "      <td>-1.389630</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.125481</td>\n",
       "      <td>1.175541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinTemp   MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n",
       "0  0.191328 -0.041360 -0.203581       0.327736      0.677819      0.623294   \n",
       "1 -0.751052  0.268745 -0.275097       0.327736     -1.124341      0.394836   \n",
       "2  0.112796  0.353318 -0.275097       0.479465      0.565184      0.851751   \n",
       "3 -0.468338  0.677518 -0.275097      -1.189550     -0.335896     -1.090136   \n",
       "4  0.835287  1.283631 -0.155903       0.100143     -0.786436      0.166379   \n",
       "\n",
       "   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am   Temp9am  \\\n",
       "0     0.081409    -1.443652    -1.457215    -1.224564  0.995479 -0.014071   \n",
       "1    -1.318948    -1.297105    -1.026898    -1.119521  0.608406  0.032447   \n",
       "2    -1.630138    -1.052860    -1.472054    -0.984466  0.608406  0.621667   \n",
       "3    -1.267083    -1.736746     0.011799    -0.369217  0.608406  0.171999   \n",
       "4     0.651924    -0.906314    -0.997221    -1.389630  0.608406  0.125481   \n",
       "\n",
       "    Temp3pm  RainToday  RainTomorrow  \n",
       "0  0.023104          0             0  \n",
       "1  0.387799          0             0  \n",
       "2  0.227333          0             0  \n",
       "3  0.708731          0             0  \n",
       "4  1.175541          0             0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df_rain_ready = pd.get_dummies(df_rain, prefix = ['Date'], columns = ['Date'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['Location'], columns = ['Location'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindGustDir'], columns = ['WindGustDir'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindDir9am'], columns = ['WindDir9am'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindDir3pm'], columns = ['WindDir3pm'])\n",
    "\n",
    "# df_rain_ready=df_rain;\n",
    "# df_rain_ready.drop('Date', inplace=True, axis=1)\n",
    "# df_rain_ready.drop('Location', inplace=True, axis=1)\n",
    "# df_rain_ready.drop('WindGustDir', inplace=True, axis=1)\n",
    "# df_rain_ready.drop('WindDir9am', inplace=True, axis=1)\n",
    "# df_rain_ready.drop('WindDir3pm', inplace=True, axis=1)\n",
    "\n",
    "# df_rain_ready=df_rain;\n",
    "# df_rain_ready.drop('Date', inplace=True, axis=1)\n",
    "# df_rain_ready.drop('Location', inplace=True, axis=1)\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindGustDir'], columns = ['WindGustDir'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindDir9am'], columns = ['WindDir9am'])\n",
    "# df_rain_ready = pd.get_dummies(df_rain_ready, prefix = ['WindDir3pm'], columns = ['WindDir3pm'])\n",
    "\n",
    "df_rain_ready.drop('Date', inplace=True, axis=1)\n",
    "df_rain_ready.drop('Location', inplace=True, axis=1)\n",
    "df_rain_ready.drop('WindGustDir', inplace=True, axis=1)\n",
    "df_rain_ready.drop('WindDir9am', inplace=True, axis=1)\n",
    "df_rain_ready.drop('WindDir3pm', inplace=True, axis=1)\n",
    "\n",
    "# Mengganti value jika yes maka 1, jika no maka 0\n",
    "df_rain_ready['RainToday'] = df_rain_ready['RainToday'].apply(lambda x: 1 if x=='Yes' else 1 if x=='yes' else 0)\n",
    "df_rain_ready['RainTomorrow'] = df_rain_ready['RainTomorrow'].apply(lambda x: 1 if x=='Yes' else 1 if x=='yes' else 0)\n",
    "\n",
    "# Menampilkan ukuran data (instance dan attribute nya)\n",
    "print('Shape of dataframe:', df_rain_ready.shape)\n",
    "\n",
    "# Menampilkan data sebanyak 5\n",
    "df_rain_ready.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-NjVeKs7o8N",
    "outputId": "611342ba-6267-40c7-ac23-220db17e9d94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113583\n",
       "1     31877\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_rain_ready['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biAi1IPT8zND",
    "outputId": "e151ecb7-7649-4ee9-a7ef-9add1753b01b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113580\n",
       "1     31880\n",
       "Name: RainToday, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_rain_ready['RainToday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpkHH4PsISbP"
   },
   "source": [
    "## Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ws-zwtP-FiNg",
    "outputId": "b8847e41-7a9e-4f33-f5cc-78ae4a2b2a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MinTemp   MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
      "0       0.068769 -0.014866 -0.073173       0.117798      0.243628   \n",
      "1      -0.257746  0.092228 -0.094407       0.112472     -0.385850   \n",
      "2       0.037191  0.116496 -0.090705       0.158089      0.186353   \n",
      "3      -0.154992  0.224219 -0.091041      -0.393671     -0.111162   \n",
      "4       0.278962  0.428696 -0.052067       0.033445     -0.262647   \n",
      "...          ...       ...       ...            ...           ...   \n",
      "145455 -0.481617  0.009517 -0.089913      -0.215226     -0.036157   \n",
      "145456 -0.421047  0.092755 -0.085933      -0.418981     -0.034557   \n",
      "145457 -0.397975  0.195205 -0.102782      -0.075963     -0.209664   \n",
      "145458 -0.249900  0.194829 -0.099889      -0.321746     -0.040169   \n",
      "145459  0.251919 -0.265615 -0.162329      -0.209504      0.200577   \n",
      "\n",
      "        WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  \\\n",
      "0           0.224029     0.029261    -0.518890    -0.523765    -0.440143   \n",
      "1           0.135500    -0.452636    -0.445140    -0.352410    -0.384196   \n",
      "2           0.280840    -0.537490    -0.347149    -0.485366    -0.324598   \n",
      "3          -0.360771    -0.419330    -0.574760     0.003905    -0.122189   \n",
      "4           0.055566     0.217724    -0.302683    -0.333043    -0.464097   \n",
      "...              ...          ...          ...          ...          ...   \n",
      "145455     -0.281634    -0.312427    -0.439916     0.343347     0.247172   \n",
      "145456     -0.340530    -0.217589    -0.466218     0.277161     0.179979   \n",
      "145457     -0.407299    -0.318387    -0.502879     0.192905     0.086317   \n",
      "145458     -0.478790    -0.347091    -0.488725     0.101268     0.067541   \n",
      "145459     -0.104035    -0.227404    -0.448324     0.234617     0.233728   \n",
      "\n",
      "        Cloud9am   Temp9am   Temp3pm  RainToday  RainTomorrow  \n",
      "0       0.357803 -0.005057  0.008304        0.0           0.0  \n",
      "1       0.208792  0.011135  0.133085        0.0           0.0  \n",
      "2       0.200604  0.204976  0.074956        0.0           0.0  \n",
      "3       0.201347  0.056921  0.234548        0.0           0.0  \n",
      "4       0.203190  0.041907  0.392597        0.0           0.0  \n",
      "...          ...       ...       ...        ...           ...  \n",
      "145455  0.198853 -0.349220  0.036159        0.0           0.0  \n",
      "145456  0.190050 -0.295012  0.130252        0.0           0.0  \n",
      "145457  0.227314 -0.260163  0.242997        0.0           0.0  \n",
      "145458 -0.341278 -0.106454  0.230860        0.0           0.0  \n",
      "145459  0.587413 -0.182147 -0.063839        0.0           0.0  \n",
      "\n",
      "[145460 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalisasi Data\n",
    "d = preprocessing.normalize(df_rain_ready)\n",
    "df_rain_normalize = pd.DataFrame(d, columns=df_rain_ready.columns)\n",
    "print(df_rain_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsl1BqVh8whF"
   },
   "source": [
    "## Split Dataset for Training and Testing\n",
    "\n",
    "Untuk menyelesaikan langkah data pre-processing, kita akan membagi data menjadi dua dataset, training dan testing. Dalam hal ini karena kita memiliki data yang cukup, kita akan membagi data dengan rasio 80:20 masing-masing untuk training dan testing. Ini akan menghasilkan data training yang memiliki 116368 baris dan 29092 baris untuk data testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a58WrxCd85tg",
    "outputId": "1ec014a2-d6c6-4af2-aa03-532cf2588627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training feature: (116368, 14)\n",
      "Shape of testing feature: (29092, 14)\n",
      "Shape of training label: (116368,)\n",
      "Shape of testing label: (29092,)\n"
     ]
    }
   ],
   "source": [
    "# Membagi dataset menjadi 2 untuk training dan testing dengan rasio 80:20\n",
    "\n",
    "# Pilih Features\n",
    "feature = df_rain_normalize.drop('RainTomorrow', axis=1)\n",
    "\n",
    "# Pilih Target\n",
    "target = df_rain_normalize['RainTomorrow']\n",
    "\n",
    "# Set Training dan Testing Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature , target, \n",
    "                                                    shuffle = True, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Menampilkan Training dan Testing Data\n",
    "print('Shape of training feature:', X_train.shape)\n",
    "print('Shape of testing feature:', X_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of testing label:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsl1BqVh8whF"
   },
   "source": [
    "## Clustering menggunakan K-Means\n",
    "\n",
    "Dalam algoritma K-means, similarity matrix yang umum digunakan untuk mengukur jarak antara titik data adalah Euclidean distance. Metrik ini paling sering digunakan dalam K-means karena sederhana diimplementasikan dan bekerja dengan baik dalam banyak kasus.\n",
    "\n",
    "Jarak Euclidean antara dua titik dalam ruang n-dimensi dihitung menggunakan rumus berikut:\n",
    "\n",
    "<div align='center'><img src='https://raw.githubusercontent.com/BayuSuryaAtmoko/rain-australia/main/euclidean_distance.png' height='250'></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "class Kmeans:\n",
    "    def __init__(self,X,K):\n",
    "        self.X=X\n",
    "        self.Output={}\n",
    "        self.Centroids=np.array([]).reshape(self.X.shape[1],0)\n",
    "        self.K=K\n",
    "        self.m=self.X.shape[0]\n",
    "        \n",
    "    def kmeanspp(self,X,K):\n",
    "        i=rd.randint(0,X.shape[0])\n",
    "        Centroid_temp=np.array([X[i]])\n",
    "        for k in range(1,K):\n",
    "            D=np.array([]) \n",
    "            for x in X:\n",
    "                D=np.append(D,np.min(np.sum((x-Centroid_temp)**2)))\n",
    "            prob=D/np.sum(D)\n",
    "            cummulative_prob=np.cumsum(prob)\n",
    "            r=rd.random()\n",
    "            i=0\n",
    "            for j,p in enumerate(cummulative_prob):\n",
    "                if r<p:\n",
    "                    i=j\n",
    "                    break\n",
    "            Centroid_temp=np.append(Centroid_temp,[X[i]],axis=0)\n",
    "        return Centroid_temp.T\n",
    "    \n",
    "    def fit(self,n_iter):\n",
    "        #randomly Initialize the centroids\n",
    "        self.Centroids=self.kmeanspp(self.X,self.K)\n",
    "        \n",
    "        \"\"\"for i in range(self.K):\n",
    "            rand=rd.randint(0,self.m-1)\n",
    "            self.Centroids=np.c_[self.Centroids,self.X[rand]]\"\"\"\n",
    "        \n",
    "        # menghitung euclidian distances and assign clusters\n",
    "        for n in range(n_iter):\n",
    "            EuclidianDistance=np.array([]).reshape(self.m,0)\n",
    "            for k in range(self.K):\n",
    "                tempDist=np.sum((self.X-self.Centroids[:,k])**2,axis=1)\n",
    "                EuclidianDistance=np.c_[EuclidianDistance,tempDist]\n",
    "            C=np.argmin(EuclidianDistance,axis=1)+1\n",
    "            #adjust the centroids\n",
    "            Y={}\n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=np.array([]).reshape(2,0)\n",
    "            for i in range(self.m):\n",
    "                Y[C[i]]=np.c_[Y[C[i]],self.X[i]]\n",
    "        \n",
    "            for k in range(self.K):\n",
    "                Y[k+1]=Y[k+1].T\n",
    "            for k in range(self.K):\n",
    "                self.Centroids[:,k]=np.mean(Y[k+1],axis=0)\n",
    "                \n",
    "            self.Output=Y\n",
    "            \n",
    "    \n",
    "    def predict(self):\n",
    "        return self.Output,self.Centroids.T\n",
    "    \n",
    "    def WCSS(self):\n",
    "        wcss=0\n",
    "        for k in range(self.K):\n",
    "            wcss+=np.sum((self.Output[k+1]-self.Centroids[:,k])**2)\n",
    "        return wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_rain_normalize.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memilih subset dari data \n",
    "\n",
    "# # X = df_rain_normalize.iloc[:,:].values\n",
    "\n",
    "# # X = df_rain_normalize.iloc[:, [3, 4]].values\n",
    "\n",
    "# # X = df_rain_normalize.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]].values\n",
    "\n",
    "# X = df_rain_normalize.iloc[:, [2,13,14]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # memperoleh ringkasan statistik dari dari setiap atribut dalam dataset\n",
    "\n",
    "# df_rain_normalize.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "\n",
    "# m=X.shape[0]\n",
    "# n_iter=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method\n",
    "\n",
    "Pada bagian ini akan dilakukan uji coba untuk menentukan jumlah cluster yang tepat berdarkan nilai SSE (Sum of Square Error) yang mengalami penurunan drastis. Semakin besar nilai SSE, semakin berkurang kualitas cluster, begitu sebaliknya. Semakin kecil nilai SSE, semakin baik kualitas cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menggunakan elbow method untuk mencari jumlah cluster yang optimal\n",
    "\n",
    "# wcss = []\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "#     kmeans.fit(X)\n",
    "#     wcss.append(kmeans.inertia_)\n",
    "    \n",
    "# plt.plot(range(1, 11), wcss)\n",
    "# plt.title('The Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada grafik di atas terlihat bahwa pada saat jumlah cluster k=1 menunjukkan nilai SSE paling tinggi, lalu saat jumlah cluster k=2 nilai SSE mengalami penurunan signifikan. Saat jumlah cluster k=3 nilai SSE mengalami penurunan kembali, begitu juga seterusnya sampai jumlah cluster k=10 mengalami penurunan juga. \n",
    "\n",
    "Berdasarkan grafik tersebut dapat dilihat jumlah cluster yang membentuk siku terlihat jelas saat jumlah cluster k=3, sedangkan pada jumlah cluster k=4 hingga k=10 terlihat mulai stabil, maka ditetapkan siku terletak pada jumlah cluster k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting K-Means to the dataset\n",
    "# kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
    "# y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menampilkan hasil dari clustering\n",
    "# plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 10, c = 'red', label = 'Cluster 1')\n",
    "# plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 10, c = 'blue', label = 'Cluster 2')\n",
    "# plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 10, c = 'green', label = 'Cluster 3')\n",
    "# plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 10, c = 'magenta', label = 'Cluster 4')\n",
    "# plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 50, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "# plt.title('Clusters of rains')\n",
    "# plt.xlabel('Annual rains')\n",
    "# plt.ylabel('Spending Score')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "After making sure our data is good and ready we can continue to building our model. In this notebook we will try to build 4 different models with different algorithm. In this step we will create a baseline model for each algorithm using the default paramaeters set by sklearn and after building all 4 of our models we will compare them to see which works best for our case.\n",
    "\n",
    "To evaluate our model we will use the confusion matrix as our base for the evaluation.\n",
    "\n",
    "<div align='center'><img src='https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png' height='250'></div>\n",
    "where: TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.\n",
    "\n",
    "We will use 6 metrics below to evaluate models:\n",
    "\n",
    "1. Accuracy: the proportion of true results among the total number of cases examined.\n",
    "<div align='center'>$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$</div>\n",
    "2. Precision: used to calculate how much proportion of all data that was predicted positive **was** actually positive.\n",
    "<div align='center'>$Precision = \\frac{TP}{TP+FP}$</div>\n",
    "3. Recall: used to calculate how much proportion of actual positives is correctly classified.\n",
    "<div align='center'>$Recall = \\frac{TP}{TP+FN}$</div>\n",
    "4. F1 score: a number between 0 and 1 and is the harmonic mean of precision and recall.\n",
    "<div align='center'>$F1 = \\frac{2TP}{2TP+FP+FN}$</div>\n",
    "5. Area Under Curve (AUC): indicates how well the probabilities from the positive classes are separated from the negative classes\n",
    "\n",
    "In this case we want to focus on the recall value of our model because in our problem we should try to predict as many actual positive as we can. Because a misclassification of customer who **actually** wanted to make a deposit can mean a lose opportunity/revenue.\n",
    "\n",
    "Below we will define a helper function to evaluate each trained model and with the metrics mentioned above and save the score to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Predict Test Data\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, f1-score\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    prec = metrics.precision_score(y_test, y_pred)\n",
    "    rec = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate area under curve (AUC)\n",
    "    y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Display confussion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1,\n",
    "            'fpr': fpr, 'tpr': tpr, 'auc': auc, 'cm': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision tree is a tree shaped diagram used to determine a course of action. Each branch of the tree represents a possible decision, occurrence or reaction.\n",
    "\n",
    "Example :\n",
    "\n",
    "<div align='center'><img src='https://raw.githubusercontent.com/rafiag/DTI2020/main/images/decision_tree.PNG' height='250'></div>\n",
    "\n",
    "Advantages:\n",
    "* Inexpensive to construct\n",
    "* Extremely fast at classifying unknown records\n",
    "* Easy to interpret for small-sized treesâ€¢\n",
    "* Accuracy is comparable to other classification techniques for many simple data sets\n",
    "\n",
    "Disadvantages:\n",
    "* Overfitting when algorithm capture noise in the data\n",
    "* The model can get unstable due to small variation of data\n",
    "* Low biased tree: difficult for the model to work with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Building Decision Tree model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dtc \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bayu/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bayu/lib/python3.10/site-packages/sklearn/tree/_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/bayu/lib/python3.10/site-packages/sklearn/utils/multiclass.py:207\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    199\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m ]:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Building Decision Tree model\n",
    "dtc = tree.DecisionTreeClassifier(random_state=0)\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "dtc_eval = evaluate_model(dtc, X_test, y_test)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print('Accuracy:', dtc_eval['acc'])\n",
    "print('Precision:', dtc_eval['prec'])\n",
    "print('Recall:', dtc_eval['rec'])\n",
    "print('F1 Score:', dtc_eval['f1'])\n",
    "print('Area Under Curve:', dtc_eval['auc'])\n",
    "print('Confusion Matrix:\\n', dtc_eval['cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimisation\n",
    "\n",
    "On the next part of this notebook, we will try to optimise our Decision Tree model by tuning the hyper parameters available from the scikit-learn library. After finding the optimal parameters we will then evaluate our new model by comparing it against our base line model before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameter with GridSearchCV\n",
    "\n",
    "We will use `GridSearchCV` functionality from sklearn to find the optimal parameter for our model. We will provide our baseline model (named `rf_grids`), scoring method (in our case we will use recall as explained before), and also various parameters value we want to try with our model. The `GridSearchCV` function will then iterate through each parameters combination to find the best scoring parameters.\n",
    "\n",
    "This function also allow us to use cross validation to train our model, where on each iteration our data will be divided into 5 (the number are adjustable from the parameter) fold. The models then will be trained on 4/5 fold of the data leaving the final fold as validation data, this process will be repeated for 5 times until all of our folds are used as validation data.\n",
    "\n",
    "<div align='center'><img src='https://i.imgur.com/9k60cVA.png' height='200'></div>\n",
    "\n",
    "To see the result of which parameters combination works best we can access the `best_params_` attribute from our grid search object.\n",
    "\n",
    "*Note: The more combination provided, the longer the process will take. Alternatively, you can also try `RandomizedSearchCV` to only randomly select specified number of parameters which can result in faster running time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "# Buat parameter grid berdasarkan hasil dari decision tree\n",
    "param_grid = {\n",
    "    'max_leaf_nodes': list(range(2, 100)),\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "# Buat base model\n",
    "rf_grids = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Initiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf_grids, param_grid=param_grid, verbose=2, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Setting parameter yang memberikan hasil terbaik pada data\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Optimised Model\n",
    "\n",
    "After finding the best parameter for the model we can access the `best_estimator_` attribute of the GridSearchCV object to save our optimised model into variable called `best_grid`. We will calculate the 6 evaluation metrics using our helper function to compare it with our base model on the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model with best fit\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate model\n",
    "best_grid_eval = evaluate_model(best_grid, X_test, y_test)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print('Accuracy:', best_grid_eval['acc'])\n",
    "print('Precision:', best_grid_eval['prec'])\n",
    "print('Recall:', best_grid_eval['rec'])\n",
    "print('F1 Score:', best_grid_eval['f1'])\n",
    "print('Area Under Curve:', best_grid_eval['auc'])\n",
    "print('Confusion Matrix:\\n', best_grid_eval['cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "The code below will draw the same plot as before only with our original Decision Tree model and it's optimised version. It will also print the change on each evaluation metrics to help us see if our optimised model work better than the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitialize figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Model Comparison', fontsize=16, fontweight='bold')\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(14)\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "# Grafik pertama\n",
    "## Menentukan ukuran bar dari grafik\n",
    "barWidth = 0.2\n",
    "## Decision tree data\n",
    "dtc_score = [dtc_eval['acc'], dtc_eval['prec'], dtc_eval['rec'], dtc_eval['f1']]\n",
    "## Naive bayes data\n",
    "best_grid_score = [best_grid_eval['acc'], best_grid_eval['prec'], best_grid_eval['rec'], best_grid_eval['f1']]\n",
    "\n",
    "## Set posisi dari bar di X axis\n",
    "r1 = np.arange(len(dtc_score))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "## Make the plot\n",
    "ax1.bar(r1, dtc_score, width=barWidth, edgecolor='white', label='Decision Tree (Base Line)')\n",
    "ax1.bar(r2, best_grid_score, width=barWidth, edgecolor='white', label='Decision Tree (Optimized)')\n",
    "\n",
    "## Add xticks on the middle of the group bars\n",
    "ax1.set_xlabel('Metrics', fontweight='bold')\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "ax1.set_xticks([r + (barWidth * 0.5) for r in range(len(dtc_score))], )\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_ylabel('Score', fontweight='bold')\n",
    "\n",
    "## Menampilkan judul grafik\n",
    "ax1.set_title('Evaluation Metrics', fontsize=14, fontweight='bold')\n",
    "## Menampilkan legend grafik\n",
    "ax1.legend()\n",
    "\n",
    "# Grafik kedua\n",
    "## Membandingkan ROC Curve\n",
    "ax2.plot(dtc_eval['fpr'], dtc_eval['tpr'], label='Decision Tree, auc = {:0.5f}'.format(dtc_eval['auc']))\n",
    "ax2.plot(best_grid_eval['fpr'], best_grid_eval['tpr'], label='Decision Tree, auc = {:0.5f}'.format(best_grid_eval['auc']))\n",
    "\n",
    "## Configure x and y axis\n",
    "ax2.set_xlabel('False Positive Rate', fontweight='bold')\n",
    "ax2.set_ylabel('True Positive Rate', fontweight='bold')\n",
    "\n",
    "## Menampilkan judul grafik\n",
    "ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "## Menampilkan legend grafik\n",
    "ax2.legend(loc=4)\n",
    "\n",
    "# Menampilkan grafik\n",
    "plt.show()\n",
    "\n",
    "# Menampilkan presentase perubahan\n",
    "print('Change of {:0.2f}% on accuracy.'.format(100 * ((best_grid_eval['acc'] - dtc_eval['acc']) / dtc_eval['acc'])))\n",
    "print('Change of {:0.2f}% on precision.'.format(100 * ((best_grid_eval['prec'] - dtc_eval['prec']) / dtc_eval['prec'])))\n",
    "print('Change of {:0.2f}% on recall.'.format(100 * ((best_grid_eval['rec'] - dtc_eval['rec']) / dtc_eval['rec'])))\n",
    "print('Change of {:0.2f}% on F1 score.'.format(100 * ((best_grid_eval['f1'] - dtc_eval['f1']) / dtc_eval['f1'])))\n",
    "print('Change of {:0.2f}% on AUC.'.format(100 * ((best_grid_eval['auc'] - dtc_eval['auc']) / dtc_eval['auc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result show that our optimised performed little bit better than the original model. The optimised models show an increase in 4 out of the 6 metrics but perform worse in the other metrics, especially the recall with -4.34% decrease. Because we want to focus on predicting as many actual positive values as possible we should stick with our original model for the prediction because it has higher recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "\n",
    "We have our model, what next? As data scientist it's important to be able to develop a model with good re-usability. In this final part I will explain on how to create a prediction based on new data and also how to save (and load) your model using `joblib` so you can use it in production or just save it for later use without having to repeat the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memprediksi hasil yang diharapkan dari semua baris dari kumpulan data\n",
    "df_shill['shill_bidding_prediction'] = dtc.predict(feature)\n",
    "\n",
    "# Menambahkan attribute shill_bidding_prediction yang berisi data \"yes\" atau \"no\"\n",
    "df_shill['shill_bidding_prediction'] = df_shill['shill_bidding_prediction'].apply(lambda x: 'yes' if x==1 else 'no')\n",
    "\n",
    "# Menyimpan dataframe baru ke csv file\n",
    "df_shill.to_csv('shill_bidding_prediction.csv', index=False)\n",
    "\n",
    "# Menampilkan data sebanyak 10\n",
    "df_shill.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model\n",
    "\n",
    "We can also save our model for further model reusability. This model can then be loaded on another machine to make new prediction without doing the whole training process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Menyimpan model untuk penggunaan selanjutnya\n",
    "dump(dtc, 'shill_bidding_classification.joblib')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
